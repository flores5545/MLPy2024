{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-34f9557d-8f15-494e-8d65-74c8ae429c5c",
    "deepnote_cell_type": "markdown",
    "id": "6Og4DnJPrB4A"
   },
   "source": [
    "# Week 7 - Logistic regression\n",
    "by Colin Rundel & David Elliott & Ozan Evkaya\n",
    "\n",
    "1. [Setup](#setup)\n",
    "\n",
    "2. [Binary Logistic Regression](#RBH)\n",
    "\n",
    "3. [Model refinement](#refine)\n",
    "\n",
    "4. [Multi-class Example](#mclog)\n",
    "\n",
    "5. [Regularization Example](#SKV)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdHUSbWsvZ7h"
   },
   "source": [
    "This week we will be implementing the logistic regression techniques from this weeks lecture in python. We will start with the binary case and then look at some extensions of the logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-645a25eb-6010-425a-88c0-ecf0093a9edc",
    "deepnote_cell_type": "markdown",
    "id": "6sVlUI4SvZ7i"
   },
   "source": [
    "---\n",
    "\n",
    "# 1. Setup <a id='setup'></a>\n",
    "\n",
    "## 1.1. Uploading your data to the colab\n",
    "This notebook will be saved in your google drive in a folder \"Colab Notebooks\" by default, you should be fairly familiar with this by now.\n",
    "\n",
    "When you run this cell you will need to give colab permission to access files in your drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ZeTuzK-dvZ7j",
    "outputId": "7f32fa7d-68bd-4d1b-fe10-6c37e41c5f27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "week07.ipynb  week-07.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "os.chdir('drive/My Drive/Colab Notebooks/mlp/week-7')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trxL3QeSvZ7k"
   },
   "source": [
    "We will now unzip the workshop materials and place them in a subdirectory \"ws-material/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "5DbL_UYJvZ7k",
    "outputId": "78a8f7fd-07a7-479e-d8c3-c69cc870ceb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping materials...\n",
      "Archive:  week-07.zip\n",
      "   creating: ws-material/week-07/\n",
      "   creating: ws-material/week-07/Data/\n",
      "  inflating: ws-material/week-07/Data/Default.csv  \n",
      "   creating: ws-material/week-07/Images/\n",
      "  inflating: ws-material/week-07/Images/pairplot.png  \n",
      "  inflating: ws-material/week-07/Images/UoE_Horizontal_Logo_282_v1_160215.png  \n",
      "   creating: ws-material/week-07/scripts/\n",
      "  inflating: ws-material/week-07/scripts/create_widgets.js  \n",
      "  inflating: ws-material/week-07/scripts/create_widgets.py  \n",
      "  inflating: ws-material/week-07/scripts/environment.yml  \n",
      "  inflating: ws-material/week-07/scripts/requirements.txt  \n",
      "  inflating: ws-material/week-07/scripts/show_solutions.py  \n",
      "week-07\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('ws-material'):\n",
    "  print('Unzipping materials...')\n",
    "  !unzip week-07.zip -d ws-material\n",
    "else:\n",
    "  print(\"Directory already exists!\")\n",
    "\n",
    "os.chdir('ws-material')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8FHFpfevZ7l"
   },
   "source": [
    "__Reminder__ \n",
    "\n",
    "- You may need to restart the runtime several times in the workshop, but you will not need to re-upload or unzip files again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEIja_2pvZ7n"
   },
   "source": [
    "## 1.2 Packages\n",
    "\n",
    "Now lets load in the packages you wil need for this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00002-d0af5d8f-8894-4c5a-b754-353993666790",
    "collapsed": true,
    "deepnote_cell_type": "code",
    "id": "grVNp8GrrH0g",
    "output_cleared": true
   },
   "outputs": [],
   "source": [
    "# Display plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting defaults\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "plt.rcParams['figure.dpi'] = 80\n",
    "\n",
    "# sklearn modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Other necessary packages\n",
    "from sklearn.datasets import load_iris           # for the Iris data\n",
    "from IPython.display import Image                # displaying .png images\n",
    "from sklearn.preprocessing import StandardScaler # scaling features\n",
    "from sklearn.preprocessing import LabelEncoder   # binary encoding\n",
    "from sklearn.pipeline import Pipeline            # combining classifier steps\n",
    "from sklearn.preprocessing import PolynomialFeatures # make PolynomialFeatures\n",
    "import warnings # prevent warnings\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold, StratifiedKFold #About randomized search over parameters\n",
    "from scipy.stats.distributions import uniform, loguniform # About creating random C values for regularization\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8_vjOPKdqLm"
   },
   "source": [
    "##  1.3 Helper Functions\n",
    "\n",
    "Below are two helper functions we will be using in this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "A3LgZwfrdyq7"
   },
   "outputs": [],
   "source": [
    "# tidy the output into a dataframe\n",
    "# We will use for getting the summary of cross-validation results in some parts\n",
    "def tidy_scores(score_dict):\n",
    "    df = pd.DataFrame(score_dict)\n",
    "    df.loc['mean'] = df.mean()\n",
    "    df.loc['sd'] = df.std()\n",
    "    df.rename({\"test_score\":\"val_score\"}, axis=1, inplace=True)\n",
    "    df.index.name = \"fold\"\n",
    "    return df.round(2)\n",
    "\n",
    "\n",
    "# this creates the matplotlib graph to make the confmat look nicer\n",
    "# IT WORKS FOR ONLY BINARY CLASSIFICATION CASE !\n",
    "def pretty_confusion_matrix(confmat, labels, title, labeling=False, highlight_indexes=[]):\n",
    "\n",
    "    labels_list = [[\"TN\", \"FP\"], [\"FN\", \"TP\"]]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(confmat.shape[0]):\n",
    "        for j in range(confmat.shape[1]):\n",
    "            if labeling:\n",
    "                label = str(confmat[i, j])+\" (\"+labels_list[i][j]+\")\"\n",
    "            else:\n",
    "                label = confmat[i, j]\n",
    "            \n",
    "            \n",
    "            if [i,j] in highlight_indexes:\n",
    "                ax.text(x=j, y=i, s=label, va='center', ha='center',\n",
    "                        weight = \"bold\", fontsize=18, color='#32618b')\n",
    "            else:\n",
    "                ax.text(x=j, y=i, s=label, va='center', ha='center')\n",
    "       \n",
    "    # change the labels\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ax.set_xticklabels(['']+[labels[0], labels[1]])\n",
    "        ax.set_yticklabels(['']+[labels[0], labels[1]])\n",
    "\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# For ROC curve plotting function\n",
    "\n",
    "def roc_plot(threshold=0.5):\n",
    "    i = (np.abs(roc.threshold - threshold)).idxmin()\n",
    "\n",
    "    sns.lineplot(x='false positive rate', y='true positive rate', data=roc, ci=None)\n",
    "\n",
    "    plt.plot([0,1],[0,1], 'k--', alpha=0.5) # 0-1 line \n",
    "    plt.plot(roc.iloc[i,0], roc.iloc[i,1], 'r.')\n",
    "\n",
    "    plt.title(\"threshold = %.2f\" % threshold)\n",
    "    plt.show() \n",
    "\n",
    "# For iris data example \n",
    "\n",
    "def species_label(theta):\n",
    "\tif theta==0:\n",
    "\t\treturn raw_data.target_names[0]\n",
    "\tif theta==1:\n",
    "\t\treturn raw_data.target_names[1]\n",
    "\tif theta==2:\n",
    "\t\treturn raw_data.target_names[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-90709695-8746-4669-9199-fd144a6ec872",
    "deepnote_cell_type": "markdown",
    "id": "yz3bjxcbvZ7r"
   },
   "source": [
    "## 1.4 Data\n",
    "\n",
    "The dataset consists of 10000 individuals and whether their credit card has defaulted or not. Below is the column description: The main aim is to build the model using Logistic Regression and predict the accuracy of it. The included columns in the data set are as follows:\n",
    "\n",
    "* `default` - Whether the individual has defaulted\n",
    "\n",
    "* `student` - Whether the individual is the student\n",
    "\n",
    "* `balance` - The balance in the individual's account\n",
    "\n",
    "* `income` - Income of an individual\n",
    "\n",
    "We read the data into python using pandas.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "eF19U6ivvZ7r",
    "outputId": "fa3accef-409c-41d9-b61d-2ac6b5d8f4b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-45c04b0a-1ae4-4d83-80c6-5524d580180f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.62507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.13470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.13895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.49394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.49588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45c04b0a-1ae4-4d83-80c6-5524d580180f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-45c04b0a-1ae4-4d83-80c6-5524d580180f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-45c04b0a-1ae4-4d83-80c6-5524d580180f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  default      balance       income\n",
       "1      No   729.526495  44361.62507\n",
       "2      No   817.180407  12106.13470\n",
       "3      No  1073.549164  31767.13895\n",
       "4      No   529.250605  35704.49394\n",
       "5      No   785.655883  38463.49588"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_default = pd.read_csv(\"./week-07/Data/Default.csv\", index_col=0)\n",
    "\n",
    "# for now lets just drop the student varible.\n",
    "df_default = df_default.drop(\"student\", axis=1)\n",
    "df_default.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izo4A3SSvZ7t"
   },
   "source": [
    "We will begin by doing explanatory data analysis to examine the data set itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-da6d5f4b-bf6b-43f7-9751-a015e6a9924e",
    "deepnote_cell_type": "markdown",
    "id": "50AbKP76vZ7u"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 1\n",
    "\n",
    "Examine the structure of the data. Answer the following questions simply;\n",
    "\n",
    "1. Do you observe anything of note from descriptive statistics that may influence our models?\n",
    "2.  Are there any missing values? \n",
    "3. Look at how the varibles relate to each other (Response: Default, Predictors: Balance and Income) (Hint: Maybe some scatterplot and boxplot for each feature in terms of different response class will be useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-4d9907ea-c7c7-4c16-aee7-5e12c3e00cc1",
    "deepnote_cell_type": "code",
    "id": "-mG-rvtrvZ7u",
    "output_cleared": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-a3d1594c-000b-48dd-b347-dfa5410fe0a7",
    "deepnote_cell_type": "markdown",
    "id": "01HS3aS8vZ7u"
   },
   "source": [
    "---\n",
    "\n",
    "**!!! Add your text solution here !!!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6TMeCFgAJVt"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 2\n",
    "\n",
    "1. Lets now create our feature matrix and response varible.\n",
    "2.  Split the data into training and test sets (**Is there anything you should try account for when splitting the data ?**) Use the test size as $10\\%$ of the whole sample\n",
    "3. Convert your response variable into the numerical format\n",
    "\n",
    "Note: For data splitting consider the the additional argument inside of `train_test_split` function, stratify in terms of the response data set. Otherwise, without stratify argument. \n",
    "\n",
    "You can check the details from here \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xhjuXdcvZ7v"
   },
   "source": [
    "---\n",
    "\n",
    "**!!! Add your comments about the answer for Q.2 here !!!**\n",
    "\n",
    "\n",
    "\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YZt5su8C7WZ"
   },
   "source": [
    "## 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-28a7a9d1-e95b-47b7-a31c-9b247c628087",
    "deepnote_cell_type": "markdown",
    "id": "mvrOq4afvZ7z"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 3\n",
    "\n",
    "Fit a binary logistic regression model to the training data by using both balance and income as features, without any regularization. State the the accuracy score of the model over the testing data\n",
    "\n",
    "For the details of the function check out \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2qXwFXvQbBq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taUDXWD5C3mw"
   },
   "source": [
    "## 2.2 Model Predictions\n",
    "\n",
    "Unlike with our previous regression models, the fitted LogisticRegression objects provide multiple prediction methods. Specifically: predict which predicts the class label (either 0 or 1), predict_proba which predicts the class probabilities, and predict_log_proba which predicts the log probabilities of each class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-28a7a9d1-e95b-47b7-a31c-9b247c628087",
    "deepnote_cell_type": "markdown",
    "id": "ZecdeX9yQdVh"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 4\n",
    "\n",
    "Based on the above fitted logistic regression model, calculate\n",
    "\n",
    "1. the predictions of the class probabilities\n",
    "2. Calculate the mean squared error, accuracy score, AUC score of your logistic regression model's predictions. The function `mean_squared_error` , `accuracy_score` and `roc_auc_score` from `sklearn.metrics` will be useful for this. See the functions documentation if you need [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00023-04722d32-f420-4104-b25b-37656a71df76",
    "deepnote_cell_type": "code",
    "id": "3Mxs7ORhvZ71",
    "output_cleared": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-28a7a9d1-e95b-47b7-a31c-9b247c628087",
    "deepnote_cell_type": "markdown",
    "id": "z4NLHMUEdKxP"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 5\n",
    "\n",
    "Consider the pipeline for the logistic regression model simply. Run 5-fold Cross Validation for this calculation and use the helper function tidy_scores() created above for average score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vTpIe932BFz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline  # combining classifier steps\n",
    "\n",
    "# One can add more model in the dictionary\n",
    "model_dict = {\"log\": LogisticRegression(random_state=42, penalty=\"none\")}\n",
    "\n",
    "#print(model_dict[model_name]) \n",
    "\n",
    "for model_name in model_dict:\n",
    "    linear_pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", model_dict[model_name])])\n",
    "        \n",
    "scores = tidy_scores(cross_validate(linear_pipe, X_train, y_train, cv=5, return_train_score=True))\n",
    "print(scores.loc[['mean', 'sd']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uoEYNyw0Jfm"
   },
   "source": [
    "## 2.3 Performance Metrics\n",
    "\n",
    "A binary classifier can make two types of errors:\n",
    "\n",
    "- Incorrectly assign an individual __who defaults__ to the __no default__ category.\n",
    "- Incorrectly assign an individual who __does not default__ to the __default__ category.\n",
    "\n",
    "While the overall error rate is low, the error rate among individuals who defaulted is very high. From the perspective of a credit card company that is trying to identify high-risk individuals, this error rate among individuals who default may well be unacceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Szq6fbGf05A9"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 6\n",
    "\n",
    "Derive the confusion matrix for the logistic regression model with two predictors by following the above pipeline. Afterwards, derive the followings;\n",
    "\n",
    "1. False Positive Rate (FPR)\n",
    "2. True Positive Rate (Recall)\n",
    "3. Precision\n",
    "4. F1-score\n",
    "\n",
    "without using any additional built-in function from any module (You need to recall the definitions from our notes) \n",
    "\n",
    "Note that,\n",
    "\n",
    "$$\n",
    "\\text{FPR} = \\frac{\\text{FP}}{\\text{FP}+ \\text{TN}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP}+ \\text{FN}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP}+ \\text{FP}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "F1 = 2\\left(\\frac{Precision \\times Recall}{Precision + Recall}\\right)\n",
    "$$\n",
    "\n",
    "What can you say about the model performance in terms of Confusion Matrix and obtained quantities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRdjYEgP1ahd"
   },
   "outputs": [],
   "source": [
    "log_pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(random_state=42))])\n",
    "\n",
    "log_pipe.fit(X_train, y_train)\n",
    "\n",
    "# use the first classifier to predict the based on testing data    \n",
    "\n",
    "\n",
    "# get the confusion matrix as a numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQrDeC8O8-Nf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ruvl0mkhF8xL"
   },
   "source": [
    "**!!! Add your comments about the model performance here !!!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "id": "tSdhFuuUjecy"
   },
   "source": [
    "**F1-score**\n",
    "\n",
    "- F1-score is a combination of Recall and Precision. \n",
    "- It is typically used when there is an __uneven class distribution__ due to a large number of True Negatives that you are not as focused on. \n",
    "\n",
    "$$\n",
    "F1 = 2\\left(\\frac{PRE \\times REC}{PRE + REC}\\right)\n",
    "$$\n",
    "\n",
    "__Notes__\n",
    "\n",
    "- Using `sklearn.metrics` this can be gained using `f1_score(y_true=y_val, y_pred=predictions)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7foBrtx5DXO"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 7\n",
    "\n",
    "1. Calculate the $F1$ score using *f1_score* function for the logistic regression model with two predictors and compare your result with your calculation obtained in Q4 in Exercise 5 above ! \n",
    "2. Draw ROC and Precision-Recall Curve for the same model. Explain the obtained graphical results and state the difference.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClWZ7isN5ekk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqZpAT1MxolL"
   },
   "source": [
    "---\n",
    "\n",
    "**!!! Add your comments here !!!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g39XnifVPKWy"
   },
   "source": [
    "## 3.1 Model Refinement\n",
    "\n",
    "For those coming from other programming / modeling languages this may be somewhat surprising, this strange default is probably the most common reason that results from sklearn might not immediately match results from other tools. This behavior can be explicitly controlled via the penalty argument. Note that if you did wish to include a penalty on the coefficients then just like with ridge or lasso it is necessary to tune this penalty parameter. However, `LogisticRegression` does not use alpha for this tuning parameter but instead uses $C$ which is the inverse of the alpha we have been using - i.e. smaller values of $C$ imply more regularization.\n",
    "\n",
    "For our logistic regression model, lets start by looking at the effects of changing the regularization strength ($C$). Note that the default value is \n",
    "$C = 1.0$ in `LogisticRegression` function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjuQg3ty7XYG"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 8\n",
    "\n",
    "1. By completing the following the following code, derive the related graph. Based on the graphical output, discuss the effects of changing the regularization strength( $C$ ) shortly. \n",
    "\n",
    "Note: You can look at the details of `plot_decision_regions` function but not obligatory to run the code !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "id": "AMIeAU0kjec1"
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "scatter_kwargs = {'edgecolor': None, 'alpha': 0.7}\n",
    "contourf_kwargs = {'alpha': 0.2}\n",
    "scatter_highlight_kwargs = {'s': 120, 'label': 'Validation data', 'alpha': 0.7}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(15,5), ncols=2, nrows = 2)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, c in enumerate([0.01, 0.05, 1., 10.]):\n",
    "        \n",
    "        log_pipe = Pipeline([\n",
    "            (\"scaler\", ______()),\n",
    "            (\"model\", LogisticRegression(C = c, random_state=42))])\n",
    "\n",
    "        log_pipe.fit(________, _______)\n",
    "    \n",
    "        plot_decision_regions(X_train, y_train, clf = log_pipe, \n",
    "                              legend = 2, X_highlight = X_val[y_val==1],\n",
    "                              contourf_kwargs = contourf_kwargs,\n",
    "                              scatter_kwargs = scatter_kwargs,\n",
    "                              scatter_highlight_kwargs = scatter_highlight_kwargs,\n",
    "                              ax = axes[i]\n",
    "                             )\n",
    "        \n",
    "        axes[i].set_title(\"C = {}\".format(c))\n",
    "        \n",
    "    plt.suptitle(\"Logistic Regression Decision Boundaries (Defaulted Validation Data Circled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbITg5nFR3Ww"
   },
   "source": [
    "## 3.1 Grid Search\n",
    "\n",
    "Before we start searching over hyperparameters, its worth noting that some of the folds may not have the same distribution of the classes. This means we could get a validation score that may be a poor estimate of performance (for example we may have a fold with very few positive classes or more than usual). Therefore when doing our gridsearch/randomsearch, we should use a `StratifiedKFold` to ensure the distribution of classes in our folds reflects the distribution in the larger data.\n",
    "\n",
    "You can check the details for `RandomizedSearchCV` function from here \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85ckjDn8jec2"
   },
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import uniform, loguniform\n",
    "\n",
    "log_pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", LogisticRegression(C = c, random_state=42))])\n",
    "\n",
    "C_list = []\n",
    "pwr = -5\n",
    "for i in range(11):\n",
    "    C_list.append(2**pwr)\n",
    "    pwr+=2\n",
    "    \n",
    "# specify parameters and distributions to sample from\n",
    "log_param_dist = {'model__C':loguniform(C_list[0], C_list[-1])}\n",
    "\n",
    "log_rs = RandomizedSearchCV(______, \n",
    "                            param_distributions = log_param_dist,\n",
    "                            n_iter = 60, \n",
    "                            scoring = [\"accuracy\", \"f1\",\"recall\",\"precision\"], \n",
    "                            cv = StratifiedKFold(n_splits=5),\n",
    "                            refit = \"f1\", \n",
    "                            random_state = 42,\n",
    "                            return_train_score = True)\n",
    "\n",
    "log_rs.fit(______, ______)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sy2nM4wbrx9E"
   },
   "source": [
    "1. Convert your `log_rs.cv_results_` into pandas data frame and sort the values in terms \"mean_test_accuracy\" in descending order by using `sort_values` function !!!\n",
    "\n",
    "2. Look at the first 6 values in this sorted values and make comments on test accuracy !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "872OWw_fTDWz"
   },
   "outputs": [],
   "source": [
    "# About the summary of best 6 models \n",
    "# Convert your log_rs.cv_results_ into pandas data frame and sort the values in terms \n",
    "# \"mean_test_accuracy\" in descending order by using sort_values !!!\n",
    "\n",
    "# Look at the first 6 values in this sorted values and make comments on test accuracy !!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pew94RYnTVZh"
   },
   "source": [
    "##  3.2 Improving Models with Imbalances\n",
    "\n",
    "There are a number of methods available to address imbalances in a dataset when we refine our models, such as:\n",
    "\n",
    "1. Weighting the classes in the model during training,\n",
    "2. Changing the training metric,\n",
    "3. Resampling the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "id": "RaKa2Q6Jjec3"
   },
   "source": [
    "### 3.2.1. Weights\n",
    "\n",
    "During model fitting we can assign a larger penalty to wrong predictions on the minority class.\n",
    "\n",
    "The heuristic used for `class_weight=\"balanced\"` in Scikit-Learn (0.23.1) is:\n",
    "\n",
    "$$\n",
    "\\frac{n}{Nc \\times \\sum\\limits^n_{i=1}I(y_i \\in S)},\n",
    "$$\n",
    "\n",
    "where $n$ are the number of samples, $Nc$ the number of classes, $I$ is an indicator function, and $S$ contains the class elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-28a7a9d1-e95b-47b7-a31c-9b247c628087",
    "deepnote_cell_type": "markdown",
    "id": "WdZKHECXTmgU"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 9\n",
    "\n",
    "Conduct a gridsearch or randomsearch using the following code chunk, this time also looking at both `C` and `class_weight`. Has this improved performance? \n",
    "\n",
    "1. When you change your refit with other scoring alternatives rather than using \"accuracy\", what is the impact of it on the result (test recall)\n",
    "2. Is there any improvement when n_splits = 10 ?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "EjE0dt7Kjec3",
    "outputId": "aedffa0b-ce8e-4a1f-cc7e-b4d0206a3d89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-96cfb348-1255-477a-a659-44187d042015\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__class_weight</th>\n",
       "      <th>param_model__C</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>5.620905</td>\n",
       "      <td>0.973951</td>\n",
       "      <td>0.001197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>22774.162439</td>\n",
       "      <td>0.973951</td>\n",
       "      <td>0.001197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>None</td>\n",
       "      <td>215.441061</td>\n",
       "      <td>0.973951</td>\n",
       "      <td>0.001197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>None</td>\n",
       "      <td>10079.898638</td>\n",
       "      <td>0.973951</td>\n",
       "      <td>0.001197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>None</td>\n",
       "      <td>4.498096</td>\n",
       "      <td>0.973951</td>\n",
       "      <td>0.001197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96cfb348-1255-477a-a659-44187d042015')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-96cfb348-1255-477a-a659-44187d042015 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-96cfb348-1255-477a-a659-44187d042015');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   param_model__class_weight param_model__C  mean_test_accuracy  \\\n",
       "0                       None       5.620905            0.973951   \n",
       "15                      None   22774.162439            0.973951   \n",
       "58                      None     215.441061            0.973951   \n",
       "53                      None   10079.898638            0.973951   \n",
       "52                      None       4.498096            0.973951   \n",
       "\n",
       "    std_test_accuracy  \n",
       "0            0.001197  \n",
       "15           0.001197  \n",
       "58           0.001197  \n",
       "53           0.001197  \n",
       "52           0.001197  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", LogisticRegression(C = c, random_state=42))])\n",
    "    \n",
    "# specify parameters and distributions to sample from\n",
    "log_param_dist = {\n",
    "    'model__C':loguniform(C_list[0], C_list[-1]),\n",
    "    'model__class_weight': [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "bal_log_rs = RandomizedSearchCV(log_pipe, \n",
    "                            param_distributions=log_param_dist,\n",
    "                            n_iter=60, \n",
    "                            scoring = [\"accuracy\", \"f1\",\"recall\",\"precision\"], \n",
    "                            cv=StratifiedKFold(n_splits=5),\n",
    "                            refit=\"accuracy\", \n",
    "                            random_state=42,\n",
    "                            return_train_score=True)\n",
    "\n",
    "bal_log_rs.fit(X_train, y_train)\n",
    "\n",
    "# To convert it as a data frame\n",
    "bal_log_rs_df = pd.DataFrame(bal_log_rs.cv_results_)\n",
    "\n",
    "#This is sorted for accuarcy, when you change your refit argument above, be careful about that\n",
    "bal_log_rs_df.sort_values(\"mean_test_accuracy\", ascending=False)[[\"param_model__class_weight\", \n",
    "                                                                  \"param_model__C\", \n",
    "                                                                  \"mean_test_accuracy\", \n",
    "                                                                  \"std_test_accuracy\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "id": "plVHhxDvjec4"
   },
   "source": [
    "### 3.2.2 Changing Training/Validation Metric\n",
    "\n",
    "__Optimising for Accuracy__ \n",
    "\n",
    "During hyperparamter cross-validation we are choosing the model with the best __overall accuracy__. \n",
    "\n",
    "This gives us a model with the smallest possible total number of misclassified observations, irrespective of which class the errors come from$^5$. \n",
    "\n",
    "ML algorithms typically optimize a reward or cost function computed as a sum over the training examples, the decision rule is likely going to be biased toward the majority class$^9$.\n",
    "\n",
    "__Notes__\n",
    "\n",
    "- _\"In other words, the algorithm implicitly learns a model that optimizes the predictions based on the most abundant class in the dataset, in order to minimize the cost or  maximize the reward during training.\"_<sup>9</sup>.\n",
    "\n",
    "- You can check the details of `classification_report` function from here \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53D2HcEQjec4"
   },
   "outputs": [],
   "source": [
    "# This is the classification report based on the accuracy metric\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(pd.DataFrame(classification_report(y_val, \n",
    "                                   bal_log_rs.predict(X_val), \n",
    "                                   labels=None, \n",
    "                                   target_names=list(LE.classes_), \n",
    "                                   sample_weight=None, \n",
    "                                   digits=2, \n",
    "                                   output_dict=True)).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "id": "LXJNCQ4rjec4"
   },
   "source": [
    "**Note**\n",
    "\n",
    "Changing the metric for what is defined as the _\"best model\"_ can help us prioritise models that make particular errors.\n",
    "\n",
    "For example, a credit card company might particularly wish to avoid incorrectly classifying an individual who will default, whereas incorrectly classifying an individual who will not default, though still to be avoided, is less problematic. \n",
    "\n",
    "In this case, __recall__ would therefore be a useful metric to use.\n",
    "\n",
    "Rather than run another cross-validation again, provided that in `scoring` you used a list that contained \"recall\", we can just use our results data to pick the model with the best \"recall\" instead of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-28a7a9d1-e95b-47b7-a31c-9b247c628087",
    "deepnote_cell_type": "markdown",
    "id": "RaxRXbcF-5EX"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 10\n",
    "\n",
    "Conduct a the following function for the new metric, recall, and then derive a similar classification report that you observed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "id": "upqmGHZ_jec4"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "# we refit the best accuracy model on all the training data\n",
    "# so lets do that for the best other metric models\n",
    "def manual_refit(input_model, X, y, gs, metric, disp_df=[]):\n",
    "    output_model = clone(input_model)\n",
    "    \n",
    "    gs_df = pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_\"+metric, ascending=False)\n",
    "    \n",
    "    if disp_df:\n",
    "        display(gs_df[disp_df].head())\n",
    "    \n",
    "    params = gs_df[\"params\"].iloc[0]\n",
    "    output_model = output_model.set_params(**params)\n",
    "    output_model = output_model.fit(X, y)\n",
    "    \n",
    "    return output_model\n",
    "\n",
    "rec_model = manual_refit(_______, ______, ______, bal_log_rs, \"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-28a7a9d1-e95b-47b7-a31c-9b247c628087",
    "deepnote_cell_type": "markdown",
    "id": "Zvf9Dact_xwz"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 11\n",
    "\n",
    "Derive the confusion matrix for each model described above, `bal_log_rs` and `rec_model` using the confusion_matrix function. State the similarity and  differences of the obtained confusion matrices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "id": "WMdQ_gVdjec5"
   },
   "source": [
    "### 3.2.3. Resampling\n",
    "\n",
    "We can change the distribution of the classes in our training data.\n",
    "\n",
    "#### Under-Sampling\n",
    "\n",
    "A fast way to balance the data is just to randomly select a subset of the data for each class so they have the number of datapoints found in the smallest class.\n",
    "\n",
    "__Notes__\n",
    "\n",
    "- `RandomUnderSampler` is part of the Imblearn package, which allows for a lot of techniques for working with imballanced data.\n",
    "- There is a `resample` method in `scikit-learn` but Imblearn is a bit smoother to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qctA7g8tZH_C"
   },
   "source": [
    "If you want to use a sampler in a model pipeline then you can use the pipeline from imblearn. Using a sampler in a pipeline ensure you wont be training and validating your data on a smaller/larger sample than normal and get unrepresentative results!\n",
    "\n",
    "You can check some of the details for `RandomUnderSampler` from here \n",
    "\n",
    "https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n",
    "\n",
    "If you understand the following mechanism, you can write the `RandomOverSampler` case below !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "id": "Pa8blBDVjec6"
   },
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "log_pipe = ImPipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"sampler\", RandomUnderSampler(random_state=123)),\n",
    "    (\"model\", LogisticRegression(random_state=42))])\n",
    "    \n",
    "# specify parameters and distributions to sample from\n",
    "log_param_dist = {'model__C':loguniform(C_list[0], C_list[-1])}\n",
    "\n",
    "us_log_rs = RandomizedSearchCV(log_pipe, \n",
    "                            param_distributions = log_param_dist,\n",
    "                            n_iter = 60, \n",
    "                            scoring = [\"accuracy\", \"f1\",\"recall\",\"precision\"], \n",
    "                            cv = StratifiedKFold(n_splits=5),\n",
    "                            refit = \"recall\", \n",
    "                            random_state = 42,\n",
    "                            return_train_score = True)\n",
    "\n",
    "us_log_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdzVhFDNjec6"
   },
   "outputs": [],
   "source": [
    "us_log_rs_df = pd.DataFrame(us_log_rs.cv_results_)\n",
    "us_log_rs_df.sort_values(\"mean_test_recall\", ascending=False)[[\"param_model__C\", \n",
    "                                                               \"mean_test_recall\", \n",
    "                                                               \"std_test_recall\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "id": "1xk6k_W-jec6"
   },
   "source": [
    "#### Oversampling\n",
    "Data can be oversampled easily by randomly sampling from minority classes with replacement to duplicate original samples. \n",
    "\n",
    "Note:\n",
    "make sure to oversample after splitting the training and validation sets or you may \"bleed\" information into the validation sets of the model when trying to test a model\n",
    "\n",
    "In-other-words, make sure it is in a pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-28a7a9d1-e95b-47b7-a31c-9b247c628087",
    "deepnote_cell_type": "markdown",
    "id": "4qQM8VKxAybZ"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 12\n",
    "\n",
    "Create a similar pipeline for oversampling strategy for the imbalanced data. It is very similar what you observed above as in `log_pipe`\n",
    "\n",
    "Hint: Consider now `from imblearn.over_sampling import RandomOverSampler` as a starting point.\n",
    "\n",
    "After getting the results in a similar way, compare the performance in terms of undersampling or oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-021075dd-c202-41db-9f49-2b4de4efd791",
    "deepnote_cell_type": "markdown",
    "id": "ilhDv3WHvZ73"
   },
   "source": [
    "---\n",
    "# 4 Multi-class Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00027-068e26c7-da60-4c7c-8551-5f914b53af75",
    "deepnote_cell_type": "markdown",
    "id": "NtUQzMD9vZ73"
   },
   "source": [
    "For this part, basically we will use the iris data, already available to use and it has nice properties in terms of class size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJqCZmu5uZpH"
   },
   "outputs": [],
   "source": [
    "# First load the data here\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Loading data\n",
    "raw_data = load_iris()\n",
    "data_desc = raw_data.DESCR\n",
    "data = pd.DataFrame(raw_data.data, columns=raw_data.feature_names)\n",
    "\n",
    "# Some information on data set \n",
    "data.head()\n",
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-b1d09da5-a8c6-46db-a5ec-617662e344a9",
    "deepnote_cell_type": "markdown",
    "id": "kMZfWvLKvZ74"
   },
   "source": [
    "Some Visual Inspection on the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00032-d4cd3759-a588-4d95-b34e-507416ebc046",
    "deepnote_cell_type": "code",
    "id": "Rt0cuv8uvZ74",
    "output_cleared": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.pairplot(data, hue='species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00033-9aecc749-af3c-4332-a238-370b1c7febc5",
    "deepnote_cell_type": "markdown",
    "id": "jnhiFSQfvZ74"
   },
   "source": [
    "**!!! Add your comments on obtained  !!!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1kX39bpvRlW"
   },
   "source": [
    "\n",
    "Since we will be attempting to predict the species of flower which is a finite list of categorical options (ie. Setosa, Virginica, Versicolor), we need to assign a numerical value for each of the species within dummy variables. Dummy variables are variables that take binary (True=1, False=0) assignments based on every category in a given column. For example, our categories are Setosa, Virginica and Versicolor. We will have a column for each of these species and will assign a 1 or 0 for each row depending on what species they are. So a sample row representing Setosa, will have the Setosa column value of 1 and the Virginica and Versicolor values would be assigned as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00030-d0c72235-001d-4cd4-a50f-302b40d9e4d3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "deepnote_cell_type": "code",
    "id": "VcuBnGPavZ73",
    "outputId": "6e1a6cad-acb2-454e-ea14-4e1753f4d69e",
    "output_cleared": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   actual_setosa  actual_versicolor  actual_virginica species  \n",
      "0              1                  0                 0  setosa  \n",
      "1              1                  0                 0  setosa  \n",
      "2              1                  0                 0  setosa  \n",
      "3              1                  0                 0  setosa  \n",
      "4              1                  0                 0  setosa  \n",
      "setosa        50\n",
      "versicolor    50\n",
      "virginica     50\n",
      "Name: species, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Consider species_label function as a helper \n",
    "\n",
    "# data = pd.DataFrame(raw_data.data, columns=raw_data.feature_names)\n",
    "data['species'] = [species_label(theta) for theta in raw_data.target]\n",
    "#data['species_id'] = raw_data.target\n",
    "print(data.head())\n",
    "\n",
    "# Class size information\n",
    "print(data.species.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEq_asGw5d7M"
   },
   "outputs": [],
   "source": [
    "#Prepare the data set\n",
    "\n",
    "#Encoding Species columns (to numerical values)\n",
    "data['species'] = data['species'].astype('category').cat.codes\n",
    "print(data['species'])\n",
    "#Feature & Target Selection\n",
    "#features = data.select_dtypes('float').columns\n",
    "#target = ['species']\n",
    "\n",
    "# X = feature values, all the columns except the last column\n",
    "X = data.iloc[:, :-1]\n",
    "print(X.head())\n",
    "\n",
    "# y = target values, last column of the data frame\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJZMp0E13sbM"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 13\n",
    "\n",
    "1. Partition your data set into training and testing with %80-%20 ratio \n",
    "3. Create One-Vs-Rest Logistic Regression pipeline and train your model\n",
    "4. Create Multinomial Logistic Regression pipeline and train your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ow2uUjn-5H9"
   },
   "source": [
    "Under this method/strategy a multi-class classification dataset (in our case IRIS) is split into multiple binary classification chunks/datasets. Then a binary classifier (in our case SVC) is trained on each of the binary classification datasets and a prediction(s) is made using the model that has the most confidence value. The IRIS dataset will be split into individual datasets for each Species versus every other Species. Following are the details:\n",
    "\n",
    "1. Binary Classification: setosa vs versicolor\n",
    "2. Binary Classification: setosa vs virginica\n",
    "3. Binary Classification: versicolor vs virginica\n",
    "\n",
    "Side Not: The **OneVsRestClassifier** class is very easy to use and requires that a classifier that is to be used for binary classification be provided to the **OneVsRestClassifier** as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKRt-FyIB5Hq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O26qY6A_-NvN"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 14\n",
    "\n",
    "1. Test the performance of one-vs-rest and multinomial logistic models\n",
    "2. Derive the confusion matrix for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3mFzKbLCI_J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00036-fdd889c3-0b7b-449e-a815-6e1e055f9703",
    "collapsed": true,
    "deepnote_cell_type": "code",
    "id": "rqv-rPpQvZ75",
    "output_cleared": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EW10NyWz8vK-"
   },
   "source": [
    "---\n",
    "\n",
    "**!!! Add your comments on obtained  !!!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00045-2510df6f-73e5-4a95-a0e6-84c3fcfc0d85",
    "deepnote_cell_type": "markdown",
    "id": "FejpEQrxvZ77"
   },
   "source": [
    "---\n",
    "\n",
    "## 5. Regularization on logistic regression\n",
    "\n",
    "Note that regularized logistic regression is implemented using the ‘liblinear’ library, ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ solvers in scikits-learn. Note that regularization is applied by default as $L_2$.\n",
    "\n",
    "So, to compare logistic regression without any regularization, play with the parameters of `LogisticRegression` function.\n",
    "\n",
    "For this purpose, we will continue with the better model as a result of the Exercise 8 !!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVmGEX-lABk_"
   },
   "source": [
    "---\n",
    "\n",
    "### 🚩 Exercise 15\n",
    "\n",
    "1. Rebuild your models above (both one-vs-rest and multinomial logistic regression) without any regularization\n",
    "2. Derive the confusion matrix for the obtained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00048-e0a6938a-2785-45be-8495-613bd782b146",
    "deepnote_cell_type": "code",
    "id": "ZAyd-mOUvZ78",
    "output_cleared": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muyjy-HN0CpQ"
   },
   "source": [
    "---\n",
    "\n",
    "Add your text solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00086-7422c6b7-c86a-41ac-8d32-8ba6063dcba5",
    "deepnote_cell_type": "markdown",
    "id": "-ICOV5l8vZ8G"
   },
   "source": [
    "---\n",
    "\n",
    "## 7. Competing the worksheet\n",
    "\n",
    "At this point you have hopefully been able to complete all the preceeding exercises. Now \n",
    "is a good time to check the reproducibility of this document by restarting the notebook's\n",
    "kernel and rerunning all cells in order.\n",
    "\n",
    "Once that is done and you are happy with everything, you can generate your PDF and turn it in on gradescope under the `mlp-week07` assignment."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "week07.ipynb",
   "provenance": []
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "2f0f4e4a-50b4-476a-ac32-ea3a1e98d30c",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
