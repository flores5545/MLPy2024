{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNnuZONqYsb4"
   },
   "source": [
    "# Week 4: Clustering\n",
    "[Jacob Page](jacob-page.com)\n",
    "\n",
    "In this workshop we will work through a set of problems dissimilarity-based clustering. \n",
    "\n",
    "We will first generate some artificial data, building our own K-means algorithm and exploring the impact of feature engineering on the output clusters. We will then use the algorithms we built to attempt to find clusters in a \"gene expression\" dataset, before applying some hierarchical techniques. \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "As you work through the problems it will help to refer to your lecture notes. The exercises here are designed to reinforce the topics covered this week. Please discuss with the tutors if you get stuck, even early on! \n",
    "\n",
    "You should regard exercises 1 - 7 as essential; the later exercises will help reinforce the topics introduced last week. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAdywZYoZa5T"
   },
   "source": [
    "# Imports\n",
    "We will start with some simple artificial data and so will not initially need anything more complex than standard numpy and matplotlib (we'll add others later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "am3xGa8BYohT"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWAWprSdZ11V"
   },
   "source": [
    "# Exercise 1\n",
    "We will work initially with some synthetic two-dimensional data generated from three normal distributions $N(\\mathbf m, \\sigma^2 \\mathbf I)$. \n",
    "\n",
    "* Generate 500 samples normally distributed about a mean $\\begin{pmatrix} 0 \\\\ 4 \\end{pmatrix}$ with standard deviation $\\sigma = 2$\n",
    "* Generate 250 samples normally distributed about a mean $\\begin{pmatrix} 0 \\\\ -4 \\end{pmatrix}$ with standard deviation $\\sigma = 1$\n",
    "* Generate 100 samples normally distributed about a mean $\\begin{pmatrix} -4 \\\\ 0 \\end{pmatrix}$ with standard deviation $\\sigma = 0.5$\n",
    "\n",
    "Visualise your data in the plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzWG5w4SZv8q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88sftKDbd58I"
   },
   "source": [
    "# Exercise 2\n",
    "Write a function to compute a Euclidean dissimilarity for arbitrary dimension vectors. We will use it in this two-dimension example and then deploy it on a more complex problem.\n",
    "\n",
    "This might seem a little excessive because the function is very simple -- however, makings things modular in this way will allow you to update your work in future with other dissimilarity measures, while retaining full control/understanding of the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ebcH8jb7cFNf"
   },
   "outputs": [],
   "source": [
    "import scipy.linalg as la \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8N1oZ7ay0y8"
   },
   "source": [
    "# Exercise 3\n",
    "Write a function that takes a data matrix X and a number of clusters K and returns K random vectors from X. We will use this to initialise our \"mean\" vectors.\n",
    "\n",
    "Test your function by re-plotting your original data with some random choices of $\\{\\mathbf m_k^0\\}$ overlayed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQGcArvQyEH4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_LKIHQq1GfL"
   },
   "source": [
    "# Exercise 4\n",
    "Write a function that takes a sample, $\\mathbf x_i \\in \\mathbb R^D$, a dissimilarity function (like the one you wrote above) and a set of \"mean\" vectors $\\{\\mathbf m_k\\}$ and returns the index $k$ corresponding to the $\\mathbf m_k$ for which dissim($\\mathbf x_i$, $\\mathbf m_k$) is minimised.\n",
    "\n",
    "Test your function (i.e. does it work as expected)! We will be deploying everything written so far together next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pAA88Qn2cgH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxdsYKnw0YDj"
   },
   "source": [
    "# Exercise 5\n",
    "You now have all the constituent parts to build a simple K-means clustering algorithm. Write a function that does this. It should return an array of indices of length $N$ ($N$ is number of samples) which are labels for the clusters, and an array of mean vectors representing the converged cluster centres. \n",
    "\n",
    "Visualise the output on your example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDqSUw3Hznwc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJnd8p-w92xW"
   },
   "source": [
    "Run your algorithm a few times using the \"true\" number of clusters (3) and visualise the results. How do the results vary between iterations? For the cases that don't \"work\", can you reason why? What would happen to our results if we initialised many more datapoints from \"cluster 1\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6wEUy-c-rR8"
   },
   "source": [
    "- Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5hP3smx_Clo"
   },
   "source": [
    "# Exercise 6\n",
    "Write a function compute the total \"within cluster point scatter\", $W(C)$, and compute this as a function of number of clusters, $K\\in \\{2, 3, 4, 5, \\dots, 7\\}$. Can you identify the correct number of clusters by plotting the results as described in the lecture notes? Make sure to compute $W(C)$ for a given $K$ many (try 10) times and average the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bl4tERuK9Cqe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-PcAy1W_kO_"
   },
   "source": [
    "# Exercise 7\n",
    "Now standardise your original dataset and re-run the K-means algorithm a few times with $K=3$. Qualitatively, how has standardising the data impacted performance? Can you argue why you observe what you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNF-S5aCwoyC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tG5WyUN2GbiB"
   },
   "source": [
    "# Exercise 8\n",
    "Now we will load in a more complex dataset with a large feature space. \n",
    "\n",
    "The dataset is the \"NCI cancer microarray dataset\" discussed extensively in *Elements of Statistical Learning*.\n",
    "It has been constructed from 64 samples of cancerous tisses, with 6830 \"gene expressions\" (the features).  Gene expression is essentially a measurement of the amount of mRNA (messenger ribonucleic acid) associated with a particular gene function. The dataset is labelled to identify the type of cancer; though our focus remains unsupervised learning and we will use the labels only to plot. \n",
    "\n",
    "We will need pandas to read in the data.\n",
    "\n",
    "[*** Disclaimer: I have very limited knowldge of biology and apologise profusely for any inaccuracies above. From a mathematician's point of view: we have 6830 real valued features, don't worry about anything else ***]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "leJH2StnFPaI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "url_data = 'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/nci.data.csv'\n",
    "url_labels = 'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/nci.label.txt'\n",
    "\n",
    "data_train_X = pd.read_csv(url_data)\n",
    "data_train_Y = pd.read_csv(url_labels, header=None)\n",
    "\n",
    "# clean data and follow convention in the notes that features are columns:\n",
    "data_train_X = data_train_X.drop(labels='Unnamed: 0', axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H97lGxLsOa9v"
   },
   "source": [
    "Visualise the data (e.g. you could just do a contour plot of X, features vs samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tb1J3rLMNula"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mozq7WKja2gW"
   },
   "source": [
    "We now convert our pandas dataframe to a pure numpy array (feature labels are largely meaningless here).\n",
    "\n",
    "If you visualise the labels, $Y$, you will notice there are lots of inconsistencies with white space etc. Run the following code to clean up this aspect of the dataset.\n",
    "\n",
    "We also would like to avoid using strings to identify tissue types (largely for plotting reasons), so we give each tissue type an integer label and save the corresponding string in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bt5Lko-3Nwl-"
   },
   "outputs": [],
   "source": [
    "X_array = np.asarray(data_train_X)\n",
    "Y_array = np.asarray(data_train_Y).flatten()\n",
    "\n",
    "for j in range(Y_array.size):\n",
    "  Y_array[j] = Y_array[j].strip()\n",
    "\n",
    "tissue_types = list(set(Y_array))\n",
    "tissue_dict = {} # keep track of indices assigned to tissues for plotting \n",
    "\n",
    "Y_nums = np.copy(Y_array)\n",
    "tissue_num = 0\n",
    "for tissue_type in tissue_types:\n",
    "  Y_nums[Y_array == tissue_type] = tissue_num\n",
    "  tissue_dict[tissue_num] = tissue_type\n",
    "  tissue_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13qbb2jqbvhT"
   },
   "source": [
    "Perform a PCA of $\\mathbf X$. Think about the feature engineering you need to do upstream of this (i.e. remember to subtact the mean!). \n",
    "\n",
    "Could any rank truncation be justified? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlogA5O8eSDK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFxFPjebdrDr"
   },
   "source": [
    "# Exercise 9\n",
    "Plot the first two principal components of the data. Plot them in two ways and verify they give the same results: by taking inner products with the appropriate columns of $\\mathbf V$ and by using the matrices $\\mathbf U$ and $\\mathbf D$.\n",
    "\n",
    "For plotting, we have provided some code that colours the datapoints by the associated tissue type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRyX-cTqeCaW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duN1FvVNfieo"
   },
   "source": [
    "Here is code to colour by tissue type, assuming you have stored the principal components in two lists, proj_mode_1 and proj_mode_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xblpLWPofMNK"
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import random\n",
    "\n",
    "colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n",
    "color_list = [key for key in colors]\n",
    "random.shuffle(color_list)\n",
    "color_map = {}\n",
    "\n",
    "for tissue, color in zip(tissue_types, color_list):\n",
    "  color_map[tissue] = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "id": "kTyBrGZVfqWR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proj_mode_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      4\u001b[0m ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m ax\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mproj_mode_1\u001b[49m, proj_mode_2, c\u001b[38;5;241m=\u001b[39mcolors_true)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'proj_mode_1' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAJDCAYAAAA8QNGHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUe0lEQVR4nO3dX4jld3nH8c/TXQP+qxGzik2ymJZo3AtTdIxStI2V1iQ3QfAiUQwNwhJqxMuEXuiFN/WiIGJ0WUII3piLGjSWaCgUTSGmzQZikjVEtpEm2whJVCwoNGzy9GKmMh1nM2cn59ndE18vODC/3/nOmQe+zPLe3zlzTnV3AACY8QdnegAAgFcysQUAMEhsAQAMElsAAIPEFgDAILEFADBox9iqqtuq6pmqevQk91dVfbmqjlXVw1X17uWPCQCwmha5snV7kite4v4rk1y8cTuY5GsvfywAgFeGHWOru+9N8ouXWHJ1kq/3uvuTnFtVb13WgAAAq2wZr9k6P8lTm46Pb5wDAPi9t3cJj1HbnNv2M4Cq6mDWn2rMa1/72vdccsklS/jxAACzHnzwwee6e99uvncZsXU8yYWbji9I8vR2C7v7cJLDSbK2ttZHjhxZwo8HAJhVVf+52+9dxtOIdyW5buOvEt+f5Ffd/bMlPC4AwMrb8cpWVX0jyeVJzquq40k+n+RVSdLdh5LcneSqJMeS/CbJ9VPDAgCsmh1jq7uv3eH+TvLppU0EAPAK4h3kAQAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABi0UGxV1RVV9XhVHauqm7e5/w1V9Z2q+lFVHa2q65c/KgDA6tkxtqpqT5JbklyZ5ECSa6vqwJZln07y4+6+NMnlSf6hqs5Z8qwAACtnkStblyU51t1PdPfzSe5IcvWWNZ3k9VVVSV6X5BdJTix1UgCAFbRIbJ2f5KlNx8c3zm32lSTvTPJ0kkeSfLa7X1zKhAAAK2yR2KptzvWW448keSjJHyX50yRfqao//J0HqjpYVUeq6sizzz57iqMCAKyeRWLreJILNx1fkPUrWJtdn+TOXncsyU+TXLL1gbr7cHevdffavn37djszAMDKWCS2HkhycVVdtPGi92uS3LVlzZNJPpwkVfWWJO9I8sQyBwUAWEV7d1rQ3Seq6sYk9yTZk+S27j5aVTds3H8oyReS3F5Vj2T9acebuvu5wbkBAFbCjrGVJN19d5K7t5w7tOnrp5P89XJHAwBYfd5BHgBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBC8VWVV1RVY9X1bGquvkkay6vqoeq6mhV/WC5YwIArKa9Oy2oqj1JbknyV0mOJ3mgqu7q7h9vWnNukq8muaK7n6yqNw/NCwCwUha5snVZkmPd/UR3P5/kjiRXb1nz8SR3dveTSdLdzyx3TACA1bRIbJ2f5KlNx8c3zm329iRvrKrvV9WDVXXdsgYEAFhlOz6NmKS2OdfbPM57knw4yauT/LCq7u/un/y/B6o6mORgkuzfv//UpwUAWDGLXNk6nuTCTccXJHl6mzXf6+5fd/dzSe5NcunWB+ruw9291t1r+/bt2+3MAAArY5HYeiDJxVV1UVWdk+SaJHdtWfPtJB+sqr1V9Zok70vy2HJHBQBYPTs+jdjdJ6rqxiT3JNmT5LbuPlpVN2zcf6i7H6uq7yV5OMmLSW7t7kcnBwcAWAXVvfXlV6fH2tpaHzly5Iz8bACAU1FVD3b32m6+1zvIAwAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAoIViq6quqKrHq+pYVd38EuveW1UvVNXHljciAMDq2jG2qmpPkluSXJnkQJJrq+rASdZ9Mck9yx4SAGBVLXJl67Ikx7r7ie5+PskdSa7eZt1nknwzyTNLnA8AYKUtElvnJ3lq0/HxjXO/VVXnJ/lokkPLGw0AYPUtElu1zbnecvylJDd19wsv+UBVB6vqSFUdefbZZxccEQBgde1dYM3xJBduOr4gydNb1qwluaOqkuS8JFdV1Ynu/tbmRd19OMnhJFlbW9sabAAArziLxNYDSS6uqouS/FeSa5J8fPOC7r7o/76uqtuT/NPW0AIA+H20Y2x194mqujHrf2W4J8lt3X20qm7YuN/rtAAATmKRK1vp7ruT3L3l3LaR1d1/8/LHAgB4ZfAO8gAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMWii2quqKqnq8qo5V1c3b3P+Jqnp443ZfVV26/FEBAFbPjrFVVXuS3JLkyiQHklxbVQe2LPtpkr/o7ncl+UKSw8seFABgFS1yZeuyJMe6+4nufj7JHUmu3rygu+/r7l9uHN6f5ILljgkAsJoWia3zkzy16fj4xrmT+VSS776coQAAXin2LrCmtjnX2y6s+lDWY+sDJ7n/YJKDSbJ///4FRwQAWF2LXNk6nuTCTccXJHl666KqeleSW5Nc3d0/3+6Buvtwd69199q+fft2My8AwEpZJLYeSHJxVV1UVeckuSbJXZsXVNX+JHcm+WR3/2T5YwIArKYdn0bs7hNVdWOSe5LsSXJbdx+tqhs27j+U5HNJ3pTkq1WVJCe6e21ubACA1VDd2778atza2lofOXLkjPxsAIBTUVUP7vZCkneQBwAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGDQQrFVVVdU1eNVdayqbt7m/qqqL2/c/3BVvXv5owIArJ4dY6uq9iS5JcmVSQ4kubaqDmxZdmWSizduB5N8bclzAgCspEWubF2W5Fh3P9Hdzye5I8nVW9ZcneTrve7+JOdW1VuXPCsAwMpZJLbOT/LUpuPjG+dOdQ0AwO+dvQusqW3O9S7WpKoOZv1pxiT5n6p6dIGfz9npvCTPnekh2BV7t9rs32qzf6vrHbv9xkVi63iSCzcdX5Dk6V2sSXcfTnI4SarqSHevndK0nDXs3+qyd6vN/q02+7e6qurIbr93kacRH0hycVVdVFXnJLkmyV1b1tyV5LqNv0p8f5JfdffPdjsUAMArxY5Xtrr7RFXdmOSeJHuS3NbdR6vqho37DyW5O8lVSY4l+U2S6+dGBgBYHYs8jZjuvjvrQbX53KFNX3eST5/izz58ius5u9i/1WXvVpv9W232b3Xteu9qvZMAAJjg43oAAAaNx5aP+lldC+zdJzb27OGquq+qLj0Tc7K9nfZv07r3VtULVfWx0zkfL22R/auqy6vqoao6WlU/ON0zsr0F/u18Q1V9p6p+tLF3Xud8lqiq26rqmZO9NdWum6W7x25Zf0H9fyT54yTnJPlRkgNb1lyV5LtZf6+u9yf5t8mZ3Ja6d3+W5I0bX19p786e2yL7t2ndv2T9NZkfO9Nzuy2+f0nOTfLjJPs3jt98pud2W3jv/i7JFze+3pfkF0nOOdOzu3WS/HmSdyd59CT376pZpq9s+aif1bXj3nX3fd39y43D+7P+/mqcHRb53UuSzyT5ZpJnTudw7GiR/ft4kju7+8kk6W57eHZYZO86yeurqpK8LuuxdeL0jsl2uvverO/HyeyqWaZjy0f9rK5T3ZdPZb32OTvsuH9VdX6SjyY5FM42i/z+vT3JG6vq+1X1YFVdd9qm46UssndfSfLOrL/59yNJPtvdL56e8XiZdtUsC731w8uwtI/64bRbeF+q6kNZj60PjE7EqVhk/76U5KbufmH9P9icRRbZv71J3pPkw0leneSHVXV/d/9kejhe0iJ795EkDyX5yyR/kuSfq+pfu/u/h2fj5dtVs0zH1tI+6ofTbqF9qap3Jbk1yZXd/fPTNBs7W2T/1pLcsRFa5yW5qqpOdPe3TsuEvJRF/+18rrt/neTXVXVvkkuTiK0za5G9uz7J3/f6i4COVdVPk1yS5N9Pz4i8DLtqlumnEX3Uz+race+qan+SO5N80v+mzzo77l93X9Tdb+vutyX5xyR/K7TOGov82/ntJB+sqr1V9Zok70vy2Gmek9+1yN49mfUrkqmqt2T9A46fOK1Tslu7apbRK1vto35W1oJ797kkb0ry1Y2rIyfaB6yeFRbcP85Si+xfdz9WVd9L8nCSF5Pc2t3b/rk6p8+Cv3tfSHJ7VT2S9aelburu587Y0PxWVX0jyeVJzquq40k+n+RVyctrFu8gDwAwyDvIAwAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAw6H8BU0gXwe5IAxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors_true = [color_map[label] for label in Y_array]\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(proj_mode_1, proj_mode_2, c=colors_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yq6mbrgSf0p9"
   },
   "source": [
    "# Exercise 10\n",
    "Perform K-means clustering on the gene expressions. If you followed the exercises above this should be implementable in a few lines. \n",
    "\n",
    "Plot the total within-cluster scatter as a function of cluster number. Is there a natural number of clusters? How do your clusters appear when the data is plotted projected onto principal components? Make sure to initialise a large number of starting vectors to search for the best $W(C)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHAd6d6KfvLP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-MU8BTajPfc"
   },
   "source": [
    "# Exercise 11\n",
    "As a final exercise, we will construct a dendogram for the gene expression dataset. We will use the \"linkage\" function from within the scipy.cluster library. \n",
    "\n",
    "In contrast to our K-means approach, we will not implement this from scratch! \n",
    "\n",
    "Have a look at the documentation to understand the output of the linkage function and the arguments you can pass \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html\n",
    "\n",
    "Plot a dendogram (hierarchy.dendogram( ... )) for the gene expression dataset and explore the effect of different cluster dissimilarity measures discussed in the lecture (which can be selected with the \"method\" argument in the linkage function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Rr9RUCKjAwf"
   },
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
