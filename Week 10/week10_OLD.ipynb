{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eldA-sl8YsLp"
   },
   "source": [
    "# Week 10: Neural networks II -- convolutions\n",
    "[Jacob Page](jacob-page.com)\n",
    "\n",
    "In this workshop we will implement some simple convolutional neural networks in keras. We will return to the dataset we saw originally in week 3 -- the MNIST set of handwritten digits. Our goal is to use CNNs to construct low dimensional representations of these images, and to try and understand what the CNNs have \"learnt\" to do in training.  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "As you work through the problems it will help to refer to your lecture notes. The exercises here are designed to reinforce the topics covered this week. The lecture notes include a small amount of documentation on the keras library, but please ask/discuss with the tutors if you get stuck, even early on! This may the first time many of you have seen keras, and things may be a little counter intuitive initially. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hm6XqPScK-FV"
   },
   "source": [
    "# Imports\n",
    "\n",
    "We're only going to need a couple of standard libraries this week, as well as keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usEZAe6SYpV8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPReDTfaEg9X"
   },
   "source": [
    "The following code boxes will allow you to visualise your model training. Scroll back up to take a look once you get to a \"model.fit\" statement! (You'll need to refresh the dashboard with the refresh button on the top right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrvawtIhEnyj"
   },
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uenq9mV1ErLf"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --port=5036 --logdir $logdir\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeHcm_OBGhtx"
   },
   "source": [
    "# Exercise 0\n",
    "In this workshop we will return to the famous \"MNIST\" dataset of handwritten digits. \n",
    "\n",
    "You might find it helpful to look back at your workshop from week 3, or the model solutions, when getting started here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEdEaAlSnEzA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(images_all_raw_train, y_all_train), (images_all_raw_test, y_all_test) = mnist.load_data() # note we now also load the test set (compare to week 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20PZjaxiz1_I"
   },
   "source": [
    "Check the shapes of the arrays etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1648327686470,
     "user": {
      "displayName": "Jacob Page",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04818256562649201928"
     },
     "user_tz": 0
    },
    "id": "1k6toNwSzxF2",
    "outputId": "08be1ee5-e40a-45a3-eeff-848354d70947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(images_all_raw_train.shape, y_all_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiDrimqO4g6Y"
   },
   "source": [
    "We are also going to normalise to have outputs between 0 and 1 (we will use sigmoids at the output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I83jk4iM4gA4"
   },
   "outputs": [],
   "source": [
    "images_all_train = images_all_raw_train / 255. \n",
    "images_all_test = images_all_raw_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7p1SxSFH0XiV"
   },
   "source": [
    "Just like in workshop 3, it will help to store the individual digits separately. To start with we'll just be training neural nets on some of the data (the 3s). \n",
    "\n",
    "Look back at workshop 3 for code on creating a dictionary of digits, or alternatively create your own data structure that lets you access all digits of a particular class. Visualise some digits when you are done to verify you have done this correctly. \n",
    "\n",
    "Please note you should do this for both the training and test sets -- it will be useful later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xiHxAd4j0Z_n"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5q1xG24emmdu"
   },
   "source": [
    "# Exercise 1\n",
    "The first thing we're going to do is to build an \"autoencoder\" with a fairly shallow CNN. Please take a look at the lecture notes for details on what the goal is with this architecture and also some example code in keras for the layer creation. \n",
    "\n",
    "We'll start by doing dimensionality reduction on the 3s, just like we did in week 3.\n",
    "\n",
    "For exercise 1 our first task is to build an input layer. Recall that convolutions are designed to look at images with multiple channels. With that in mind, modify the input data accordingly and then create an input layer in keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mLphmtx1eX5"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R_1TGs8rInz"
   },
   "source": [
    "# Exercise 2 \n",
    "Create two convolutional + max pooling layers to shrink the dimension of the image. You are free to specify the filter size, padding strategy and number of filters. To avoid very long training times, I would recommend keeping the number of filters low, however. (For example, in the model solution I used 16 in the first layer, 8 in the second.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HhzuQdIuptAh"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAtBj2cRs6RZ"
   },
   "source": [
    "# Exercise 3 \n",
    "Now let's create a decoder as convolution -> upsampling -> convolution -> upsampling, followed by a final convolution to return an image of the same shape as the input. This can be harder than it looks! Remember you can visualise the properties of a model with model.summary(). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQdCePvVZqkE"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csTjsKWkzj3I"
   },
   "source": [
    "# Exercise 4\n",
    "Now compile the model for the whole autoencoder ready for training. \n",
    "\n",
    "What is the appropriate loss here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sIffhO8zjXE"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQWS_8eY9pQj"
   },
   "source": [
    "Train the model. You might have to wait a minute or two for this. If you're training on full resolution data then I would recommend only running a few epochs. You may want to enable GPU support in the runtime to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQwx1c7D9npS"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgyMFi6K1gFE"
   },
   "source": [
    "# Exercise 5\n",
    "Visualise the prediction of some 3s from the test set. \n",
    "\n",
    "You may want to explore the effect of changing various hyperparameters at this point (e.g. filter numbers, pooling strategies...). Can you think of any modification to your architecture that would allow you to fix the embedding dimension and change the convolutional structure? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFj2q0lj1quC"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qcl7L-v812b"
   },
   "source": [
    "# Exercise 6 \n",
    "Visualise the output of the first set of convolutions, and then the second set for several different channels.\n",
    "\n",
    "Are any of the features interpretable?\n",
    "\n",
    "Some code below is included to help you get started. We create a new input layer, and extract the first layer from a trained model \"autoencoder\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0ab7ZKs80jV"
   },
   "outputs": [],
   "source": [
    "input_layer_vis = keras.layers.Input(shape=(Nx,Ny,1))\n",
    "first_conv = autoencoder.layers[1](input_layer_vis) \n",
    "first_con_model = keras.models.Model(input_layer_vis, first_conv)\n",
    "first_con_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBktoIRAAzQV"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IT0n4-vxR51v"
   },
   "source": [
    "# Exercise 7\n",
    "Create two models from your trained autoencoder. One model should be the \"encoder\" module, which runs from the input to the layer where the output dimension is smallest. The second should be the \"decoder\", which convert the encoded representation back into an image of a 3. \n",
    "\n",
    "**Note:** Create a new input layer for each model, but make sure to extract the trained layers from your autoencoder. You might find it helpful to use layer.input_shape or layer.output_shape to extract tensor shapes rather than manually entering them, particularly when you attempt to construct the decoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JpmuMrr0SKsi"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xh_7ODR_RuYZ"
   },
   "source": [
    "# Exercise 8\n",
    "Compute the mean 3 from the test set. Then compute the embeddings of all the threes in test set, compute the mean *embedding* and then decode. How do the results compare? Can you offer an explanation for what you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xminIzHXSr3S"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaD43AtMTDQA"
   },
   "source": [
    "# Exercise 9 (optional)\n",
    "Contaminate the images with (Gaussian) noise. Can you train a neural network to de-noise the images? Think carefully about what the objective function should be (what the \"x\" and \"y\" here)?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCof_kg5TLGR"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzPDvXGKTLdI"
   },
   "source": [
    "# Exercise 10 (optional)\n",
    "If you are able to train it, train your autoencoder to reconstruct all digits. For speeed of training you might want to reduce the size of the training set, or focus on a subset of the labels.\n",
    "\n",
    "Once this is done, build a fully connected classifier on top of your encoder. What should the loss function be? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiCXH-RcTR7Q"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMJ0g+wpcO247CmeDALJ69q",
   "collapsed_sections": [],
   "name": "week10.ipynb",
   "provenance": [
    {
     "file_id": "1rbsH-qOENezJeR5XJkpU7uhUaBuwbDM_",
     "timestamp": 1647616242630
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
